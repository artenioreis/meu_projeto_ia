import numpy as np
import nltk
import string
import random
import os
import glob
import re
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# Importa√ß√µes com tratamento de erro robusto
try:
    import docx
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False
    print("‚ö†Ô∏è  python-docx n√£o dispon√≠vel")

try:
    import PyPDF2
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False
    print("‚ö†Ô∏è  PyPDF2 n√£o dispon√≠vel")

try:
    import openpyxl
    EXCEL_AVAILABLE = True
except ImportError:
    EXCEL_AVAILABLE = False
    print("‚ö†Ô∏è  openpyxl n√£o dispon√≠vel")

try:
    import pptx
    PPTX_AVAILABLE = True
except ImportError:
    PPTX_AVAILABLE = False
    print("‚ö†Ô∏è  python-pptx n√£o dispon√≠vel")

try:
    from odf import text, teletype
    ODF_AVAILABLE = True
except ImportError:
    ODF_AVAILABLE = False
    print("‚ö†Ô∏è  odfpy n√£o dispon√≠vel")

try:
    import speech_recognition as sr
    AUDIO_AVAILABLE = True
except ImportError:
    AUDIO_AVAILABLE = False
    print("‚ö†Ô∏è  speechrecognition n√£o dispon√≠vel")

try:
    from moviepy.editor import VideoFileClip
    VIDEO_AVAILABLE = True
except ImportError:
    VIDEO_AVAILABLE = False
    print("‚ö†Ô∏è  moviepy n√£o dispon√≠vel")

class AdamIAMultimodal:
    def __init__(self):
        """
        Adam Multimodal - IA que aprende com TODOS os tipos de arquivos
        """
        self.respostas = []
        self.fontes_conhecimento = {}
        self.vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')
        self.caracteristicas = None
        
        self.estatisticas = {
            'total_sentencas': 0,
            'total_arquivos': 0,
            'arquivos_processados': [],
            'tipos_processados': {},
            'ultima_atualizacao': None,
            'erros_processamento': []
        }
        
        self._baixar_recursos_nltk()
        self._verificar_dependencias()
    
    def _baixar_recursos_nltk(self):
        """Baixa recursos do NLTK"""
        try:
            nltk.data.find('tokenizers/punkt')
        except LookupError:
            print("üì• Baixando recursos NLTK...")
            nltk.download('punkt')
    
    def _verificar_dependencias(self):
        """Verifica quais depend√™ncias est√£o dispon√≠veis"""
        print("üîç Adam Multimodal - Capacidades:")
        capacidades = []
        if DOCX_AVAILABLE: capacidades.append("üìÑ Word")
        if PDF_AVAILABLE: capacidades.append("üìë PDF") 
        if EXCEL_AVAILABLE: capacidades.append("üìä Excel")
        if PPTX_AVAILABLE: capacidades.append("üé§ PowerPoint")
        if ODF_AVAILABLE: capacidades.append("üìù OpenDocument")
        if AUDIO_AVAILABLE: capacidades.append("üéµ √Åudio")
        if VIDEO_AVAILABLE: capacidades.append("üé¨ V√≠deo")
        
        if capacidades:
            print(f"‚úÖ {', '.join(capacidades)}")
        else:
            print("‚ö†Ô∏è  Nenhuma capacidade adicional dispon√≠vel")
    
    def preprocessar_texto(self, texto):
        """Limpa e prepara o texto"""
        if not texto:
            return ""
        texto = str(texto)
        texto = texto.translate(str.maketrans('', '', string.punctuation))
        texto = texto.lower()
        texto = re.sub(r'\s+', ' ', texto)
        return texto.strip()
    
    # ========== PROCESSADORES DE ARQUIVOS ==========
    
    def processar_txt(self, arquivo_path):
        """Processa arquivos .txt"""
        try:
            # Tenta diferentes encodings
            encodings = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']
            for encoding in encodings:
                try:
                    with open(arquivo_path, 'r', encoding=encoding) as f:
                        conteudo = f.read()
                    if conteudo.strip():
                        sentencas = nltk.sent_tokenize(conteudo)
                        return [s for s in sentencas if len(s.strip()) > 5]
                except UnicodeDecodeError:
                    continue
            return []
        except Exception as e:
            self.estatisticas['erros_processamento'].append(f"TXT {os.path.basename(arquivo_path)}: {e}")
            return []
    
    def processar_docx(self, arquivo_path):
        """Processa arquivos .docx"""
        if not DOCX_AVAILABLE:
            return []
        
        try:
            doc = docx.Document(arquivo_path)
            texto_completo = []
            for para in doc.paragraphs:
                if para.text and para.text.strip():
                    texto_completo.append(para.text.strip())
            
            texto = ' '.join(texto_completo)
            if texto:
                sentencas = nltk.sent_tokenize(texto)
                return [s for s in sentencas if len(s.strip()) > 5]
            return []
        except Exception as e:
            self.estatisticas['erros_processamento'].append(f"DOCX {os.path.basename(arquivo_path)}: {e}")
            return []
    
    def processar_pdf(self, arquivo_path):
        """Processa arquivos .pdf"""
        if not PDF_AVAILABLE:
            return []
        
        try:
            texto_completo = []
            with open(arquivo_path, 'rb') as f:
                pdf_reader = PyPDF2.PdfReader(f)
                for pagina_num, pagina in enumerate(pdf_reader.pages):
                    try:
                        texto = pagina.extract_text()
                        if texto and texto.strip():
                            texto_completo.append(texto.strip())
                    except:
                        continue
            
            texto = ' '.join(texto_completo)
            if texto:
                sentencas = nltk.sent_tokenize(texto)
                return [s for s in sentencas if len(s.strip()) > 5]
            return []
        except Exception as e:
            self.estatisticas['erros_processamento'].append(f"PDF {os.path.basename(arquivo_path)}: {e}")
            return []
    
    def processar_xlsx(self, arquivo_path):
        """Processa arquivos .xlsx"""
        if not EXCEL_AVAILABLE:
            return []
        
        try:
            texto_completo = []
            workbook = openpyxl.load_workbook(arquivo_path, read_only=True)
            for sheet_name in workbook.sheetnames:
                sheet = workbook[sheet_name]
                for row in sheet.iter_rows(values_only=True):
                    linha_texto = ' '.join([str(cell) for cell in row if cell is not None and str(cell).strip()])
                    if linha_texto.strip():
                        texto_completo.append(linha_texto.strip())
            
            texto = ' '.join(texto_completo)
            if texto:
                sentencas = nltk.sent_tokenize(texto)
                return [s for s in sentencas if len(s.strip()) > 5]
            return []
        except Exception as e:
            self.estatisticas['erros_processamento'].append(f"XLSX {os.path.basename(arquivo_path)}: {e}")
            return []
    
    def processar_pptx(self, arquivo_path):
        """Processa arquivos .pptx"""
        if not PPTX_AVAILABLE:
            return []
        
        try:
            texto_completo = []
            presentation = pptx.Presentation(arquivo_path)
            for slide in presentation.slides:
                for shape in slide.shapes:
                    if hasattr(shape, "text") and shape.text and shape.text.strip():
                        texto_completo.append(shape.text.strip())
            
            texto = ' '.join(texto_completo)
            if texto:
                sentencas = nltk.sent_tokenize(texto)
                return [s for s in sentencas if len(s.strip()) > 5]
            return []
        except Exception as e:
            self.estatisticas['erros_processamento'].append(f"PPTX {os.path.basename(arquivo_path)}: {e}")
            return []
    
    def processar_odt(self, arquivo_path):
        """Processa arquivos .odt"""
        if not ODF_AVAILABLE:
            return []
        
        try:
            from odf.opendocument import load
            doc = load(arquivo_path)
            texto_completo = []
            
            # Extrai texto de par√°grafos
            for elem in doc.getElementsByType(text.P):
                texto = teletype.extractText(elem)
                if texto and texto.strip():
                    texto_completo.append(texto.strip())
            
            texto = ' '.join(texto_completo)
            if texto:
                sentencas = nltk.sent_tokenize(texto)
                return [s for s in sentencas if len(s.strip()) > 5]
            return []
        except Exception as e:
            self.estatisticas['erros_processamento'].append(f"ODT {os.path.basename(arquivo_path)}: {e}")
            return []
    
    def processar_audio(self, arquivo_path):
        """Processa arquivos de √°udio"""
        if not AUDIO_AVAILABLE:
            print(f"   ‚ö†Ô∏è  Processamento de √°udio n√£o dispon√≠vel para {os.path.basename(arquivo_path)}")
            return []
        
        try:
            recognizer = sr.Recognizer()
            
            # Verifica se √© MP3 e converte se necess√°rio
            if arquivo_path.lower().endswith('.mp3'):
                try:
                    from pydub import AudioSegment
                    audio = AudioSegment.from_mp3(arquivo_path)
                    wav_path = arquivo_path + '_temp.wav'
                    audio.export(wav_path, format="wav")
                    arquivo_audio = wav_path
                except Exception as e:
                    print(f"   ‚ö†Ô∏è  N√£o foi poss√≠vel converter MP3: {e}")
                    return []
            else:
                arquivo_audio = arquivo_path
            
            # Transcreve √°udio
            with sr.AudioFile(arquivo_audio) as source:
                audio_data = recognizer.record(source)
                texto = recognizer.recognize_google(audio_data, language='pt-BR')
                if texto:
                    sentencas = nltk.sent_tokenize(texto)
                    return [s for s in sentencas if len(s.strip()) > 5]
                return []
                
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Erro ao processar √°udio: {e}")
            self.estatisticas['erros_processamento'].append(f"√ÅUDIO {os.path.basename(arquivo_path)}: {e}")
            return []
        finally:
            # Limpa arquivo tempor√°rio se existir
            if 'wav_path' in locals() and os.path.exists(wav_path):
                os.remove(wav_path)
    
    def processar_video(self, arquivo_path):
        """Processa arquivos de v√≠deo"""
        if not VIDEO_AVAILABLE:
            print(f"   ‚ö†Ô∏è  Processamento de v√≠deo n√£o dispon√≠vel para {os.path.basename(arquivo_path)}")
            return []
        
        try:
            # Extrai √°udio do v√≠deo
            video = VideoFileClip(arquivo_path)
            audio_path = arquivo_path + "_audio.wav"
            video.audio.write_audiofile(audio_path, verbose=False, logger=None)
            
            # Processa o √°udio extra√≠do
            sentencas = self.processar_audio(audio_path)
            
            return sentencas
            
        except Exception as e:
            print(f"   ‚ö†Ô∏è  Erro ao processar v√≠deo: {e}")
            self.estatisticas['erros_processamento'].append(f"V√çDEO {os.path.basename(arquivo_path)}: {e}")
            return []
        finally:
            # Limpa arquivo tempor√°rio se existir
            if 'audio_path' in locals() and os.path.exists(audio_path):
                os.remove(audio_path)
    
    def processar_arquivo(self, arquivo_path):
        """Processa qualquer tipo de arquivo"""
        extensao = os.path.splitext(arquivo_path)[1].lower()
        nome_arquivo = os.path.basename(arquivo_path)
        
        mapeamento_processadores = {
            '.txt': self.processar_txt,
            '.docx': self.processar_docx,
            '.doc': self.processar_docx,
            '.pdf': self.processar_pdf,
            '.xlsx': self.processar_xlsx,
            '.xls': self.processar_xlsx,
            '.pptx': self.processar_pptx,
            '.ppt': self.processar_pptx,
            '.odt': self.processar_odt,
            '.rtf': self.processar_txt,  # RTF como texto simples por enquanto
            '.mp3': self.processar_audio,
            '.wav': self.processar_audio,
            '.aac': self.processar_audio,
            '.wma': self.processar_audio,
            '.ogg': self.processar_audio,
            '.mp4': self.processar_video,
            '.avi': self.processar_video,
            '.mov': self.processar_video,
            '.mkv': self.processar_video,
            '.wmv': self.processar_video,
        }
        
        processador = mapeamento_processadores.get(extensao)
        if processador:
            print(f"   üîÑ Processando {extensao.upper()}: {nome_arquivo}")
            return processador(arquivo_path)
        else:
            print(f"   ‚ùå Formato n√£o suportado: {extensao}")
            return []
    
    def aprender_tudo(self, pasta_dados="dados"):
        """Aprende com TODOS os arquivos"""
        print("üß† Adam Multimodal: Iniciando aprendizado completo...")
        
        # Reset
        self.respostas = []
        self.fontes_conhecimento = {}
        self.estatisticas.update({
            'total_sentencas': 0,
            'total_arquivos': 0,
            'arquivos_processados': [],
            'tipos_processados': {},
            'erros_processamento': []
        })
        
        if not os.path.exists(pasta_dados):
            os.makedirs(pasta_dados)
            print(f"üìÅ Pasta '{pasta_dados}' criada. Adicione arquivos!")
            return False
        
        # Encontra TODOS os arquivos
        arquivos_encontrados = glob.glob(os.path.join(pasta_dados, "*.*"))
        arquivos_encontrados = [f for f in arquivos_encontrados if os.path.isfile(f)]
        
        if not arquivos_encontrados:
            print("‚ùå Nenhum arquivo encontrado!")
            return False
        
        print(f"üìö Encontrados {len(arquivos_encontrados)} arquivos:")
        
        total_sentencas = 0
        arquivos_sucesso = 0
        
        for arquivo_path in arquivos_encontrados:
            nome_arquivo = os.path.basename(arquivo_path)
            extensao = os.path.splitext(arquivo_path)[1].lower()
            
            sentencas = self.processar_arquivo(arquivo_path)
            
            if sentencas:
                for sentenca in sentencas:
                    if len(sentenca.strip()) > 5:
                        sentenca_processada = self.preprocessar_texto(sentenca)
                        self.respostas.append(sentenca_processada)
                        self.fontes_conhecimento[len(self.respostas) - 1] = nome_arquivo
                
                total_sentencas += len(sentencas)
                arquivos_sucesso += 1
                self.estatisticas['arquivos_processados'].append(nome_arquivo)
                
                # Estat√≠sticas por tipo
                if extensao in self.estatisticas['tipos_processados']:
                    self.estatisticas['tipos_processados'][extensao] += 1
                else:
                    self.estatisticas['tipos_processados'][extensao] = 1
                
                print(f"   ‚úÖ {nome_arquivo}: {len(sentencas)} senten√ßas")
            else:
                print(f"   ‚ùå {nome_arquivo}: 0 senten√ßas (n√£o processado)")
        
        self.estatisticas['total_sentencas'] = total_sentencas
        self.estatisticas['total_arquivos'] = arquivos_sucesso
        self.estatisticas['ultima_atualizacao'] = np.datetime64('now')
        
        print(f"\nüéâ Adam aprendeu com {arquivos_sucesso}/{len(arquivos_encontrados)} arquivos!")
        print(f"üìä Total: {total_sentencas} senten√ßas")
        
        # Estat√≠sticas
        if self.estatisticas['tipos_processados']:
            print("üìà Tipos processados:")
            for tipo, qtd in self.estatisticas['tipos_processados'].items():
                print(f"   {tipo}: {qtd} arquivos")
        
        if self.estatisticas['erros_processamento']:
            print(f"‚ö†Ô∏è  {len(self.estatisticas['erros_processamento'])} erros de processamento")
        
        return arquivos_sucesso > 0
    
    def treinar_modelo(self):
        """Treina o modelo"""
        if not self.respostas:
            print("‚ùå Nenhum conhecimento para treinar!")
            return False
        
        print("‚ö° Treinando modelo...")
        try:
            self.caracteristicas = self.vectorizer.fit_transform(self.respostas)
            print("‚úÖ Modelo treinado!")
            return True
        except Exception as e:
            print(f"‚ùå Erro no treinamento: {e}")
            return False
    
    def responder_pergunta(self, pergunta):
        """Responde perguntas"""
        if self.caracteristicas is None:
            return "ü§ñ Adam: Ainda n√£o fui treinada!"
        
        pergunta_processada = self.preprocessar_texto(pergunta)
        if not pergunta_processada:
            return "ü§ñ Adam: Por favor, fa√ßa uma pergunta mais clara."
        
        try:
            pergunta_vetor = self.vectorizer.transform([pergunta_processada])
            similaridades = cosine_similarity(pergunta_vetor, self.caracteristicas).flatten()
            
            if len(similaridades) == 0:
                return "ü§ñ Adam: Ainda n√£o tenho conhecimento suficiente."
            
            indice_melhor = similaridades.argmax()
            melhor_similaridade = similaridades[indice_melhor]
            
            if melhor_similaridade < 0.1:
                respostas = [
                    "ü§î Adam: N√£o encontrei informa√ß√µes sobre isso.",
                    "üìö Adam: Isso n√£o est√° no meu conhecimento atual.",
                    "üí° Adam: Ainda n√£o aprendi sobre isso.",
                    "üéØ Adam: Hmm, n√£o tenho dados sobre isso."
                ]
                return random.choice(respostas)
            
            fonte = self.fontes_conhecimento.get(indice_melhor, "Conhecimento Geral")
            resposta = self.respostas[indice_melhor]
            
            return f"üß† Adam (aprendi de {fonte}): {resposta.capitalize()}"
            
        except Exception as e:
            return f"ü§ñ Adam: Erro ao processar pergunta: {str(e)}"
    
    def adicionar_conhecimento(self, novo_texto, fonte="Manual"):
        """Adiciona conhecimento manual"""
        sentencas = nltk.sent_tokenize(str(novo_texto))
        adicionadas = 0
        
        for sentenca in sentencas:
            if len(sentenca.strip()) > 5:
                sentenca_processada = self.preprocessar_texto(sentenca)
                self.respostas.append(sentenca_processada)
                self.fontes_conhecimento[len(self.respostas) - 1] = fonte
                adicionadas += 1
        
        if adicionadas > 0:
            self.estatisticas['total_sentencas'] = len(self.respostas)
            self.estatisticas['ultima_atualizacao'] = np.datetime64('now')
            self.treinar_modelo()
            print(f"‚úÖ Adam: Aprendi {adicionadas} novas senten√ßas!")
    
    def get_estatisticas(self):
        """Retorna estat√≠sticas"""
        return {
            'nome': 'Adam - IA Multimodal',
            'status': 'Operacional',
            'total_sentencas': self.estatisticas['total_sentencas'],
            'total_arquivos': self.estatisticas['total_arquivos'],
            'arquivos_processados': self.estatisticas['arquivos_processados'],
            'tipos_processados': self.estatisticas['tipos_processados'],
            'modelo_treinado': self.caracteristicas is not None,
            'versao': '2.0 - Multimodal',
            'erros': len(self.estatisticas['erros_processamento'])
        }